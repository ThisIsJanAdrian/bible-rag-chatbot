# ğŸ“– BibleBro: a Bible RAG Chatbot (WIP)

BibleBro is a **Retrieval-Augmented Generation (RAG) chatbot** that answers questions strictly using **Bible verses only**, specifically using the **King James Version (KJV)**. This project focuses on **grounded retrieval, verse-level accuracy, and interpretability** to ensure faithful responses from retrieved passages and minimize hallucinations.

Think of BibleBro as your **Bible study aide**, intentionally unbiased and speaks nothing but the truth.

> ğŸš§ This repository is under active development.

---

## ğŸ¯ Objectives

- Ground all answers strictly in Scripture  
- Preserve verse- and paragraph-level structure  
- Clearly separate **Scripture** from **explanation**  
- Enable exact verse referencing despite chunked embeddings  
- Build an explainable, debuggable RAG pipeline  

---

## ğŸ§  System Overview

**Pipeline:**

1. **Ingestion** â€“ Load and normalize KJV Bible text  
2. **Chunking** â€“ Verse-aware, overlapping chunks (min-word based)  
3. **Embeddings** â€“ Local embeddings using `BAAI/bge-base-en-v1.5`  
4. **Vector Store** â€“ Persistent ChromaDB storage  
5. **Retrieval** â€“ Semantic search with verse-level reconstruction  
6. **Context Formatting** â€“ Human-readable Scripture blocks  
7. **(Planned)** LLM Integration â€“ Scripture-grounded answers only  

---

## ğŸ“‚ Project Structure
```
app/
  â””â”€â”€ chat.py                     # Entry point for chatbot interface (soon)

data/
  â”œâ”€â”€ kjv_chunks.json             # Pre-chunked KJV Bible text with references
  â”œâ”€â”€ kjv_verse_indeces.json      # Mapping of chunk IDs to book/chapter/verse
  â””â”€â”€ chroma_db/                  # Local Chroma vector store (gitignored)

preprocessing/
  â”œâ”€â”€ chunking.py                 # Logic for splitting Bible text into semantic chunks
  â””â”€â”€ ingestion.py                # Loads chunks and metadata into ChromaDB

retrieval/
  â”œâ”€â”€ format_context.py           # Formats retrieved passages for LLM prompting
  â”œâ”€â”€ query_modes.py              # Heuristic detection of query intent (law, discourse, etc.)
  â”œâ”€â”€ reranking.py                # Hybrid re-ranking (embeddings + phrase overlap + query modes)
  â”œâ”€â”€ retrieval_preprocessing.py  # Query normalization, lemmatization, phrase extraction
  â”œâ”€â”€ retrieve.py                 # Vector search interface over ChromaDB
  â””â”€â”€ retrieve_and_answer.py      # End-to-end retrieval + LLM answer pipeline (to be updated)

scripts/
  â”œâ”€â”€ create_chunks.py            # One-time script to generate Bible chunks
  â”œâ”€â”€ embed_chunks.py             # Generates embeddings and populates vector store
  â””â”€â”€ test_retrieval.py           # Entry point for chunk retrieval (no LLM)

utils/
  â””â”€â”€ hf_utils.py                 # Hugging Face model and embedding helpers
```

---

## âœ… Progress

- [x] KJV ingestion and normalization  
- [x] Verse-aware chunking with overlap  
- [x] Local embeddings (CPU-based)  
- [x] Persistent vector storage (ChromaDB)  
- [x] Semantic retrieval  
- [x] Verse-level reconstruction within chunks  
- [x] Human-readable formatted context  
- [x] LLM integration with strict grounding rules  
- [x] `retrieve_and_answer.py` pipeline  
- [x] System prompt for Scripture-only answers
- [x] Retrieval evaluation & regression tests
- [ ] Improve chunk reranking intelligence
- [ ] Local UI (Streamlit)  
- [ ] Error handling and safeguards  
- [ ] Expanded documentation and examples  

---

## âš ï¸ Notes

- Vector database files are intentionally excluded from version control  
- Embeddings are generated locally and cached  
- Project prioritizes **correctness and faithfulness over speed**

---

## ğŸ“Œ Status

ğŸ› ï¸ **Active development** â€” expect iteration and refinement.
